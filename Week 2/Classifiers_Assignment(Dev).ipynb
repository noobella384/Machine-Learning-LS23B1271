{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#WELCOME\n",
        "In this Assignment, you'll use **Classifier** to predict the output. You are allowed to write/edit between the\n",
        "```# START CODE HERE``` & ```# END CODE HERE``` only.<br>\n",
        "Don't edit the test cells otherwise you'd be failed in the assignment.\n",
        "\n",
        "Upload the ```utils.zip``` file before running the 1st cell.\n",
        "[Demo](https://drive.google.com/file/d/1ebkQR6ikjGottmxa5KL83ZWdjTLvRxbm/view?usp=share_link)\n",
        "\n",
        "**BEST OF LUCK**"
      ],
      "metadata": {
        "id": "HJM8Y9mh5o4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN THIS CODE TO UNIZP THE REQUIRED FILES**"
      ],
      "metadata": {
        "id": "cEl-4aFCkdsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -j /content/utils.zip -d."
      ],
      "metadata": {
        "id": "mCdV1dV8kawl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading and Pre-Processing"
      ],
      "metadata": {
        "id": "VA4ZUSGu0Ox3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/weather_classification_data.csv\")"
      ],
      "metadata": {
        "id": "_tP5JsNsqBsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Info\n",
        "```data.info``` gives info about data-types and number of null objects.  \n",
        "There are no null data, no need to remove any."
      ],
      "metadata": {
        "id": "MBHkfY1c0gO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "O-myJ9LmqG8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Shuffling\n",
        "Data Shuffling removes any bias present and creates uniform distribution."
      ],
      "metadata": {
        "id": "98kT9K8a1LF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "data = shuffle(data)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "DJ6bkcTbz8kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling and Labeling\n",
        "Machine can't understand string so all the object datatypes need to be LABELED with integers.<br><br>\n",
        "Why SCALING?<br>\n",
        "You might have noticed one column contains data with large values (of order 1000) whereas some column contain small value data (of order 10). As a result, large value columns get more power/importance than others. To remove this disparity we scaled them to same order/values."
      ],
      "metadata": {
        "id": "7vKEzz9j19WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CODE**\n",
        "\n",
        "We need to find the columns with object datatypes.\n",
        "\n",
        "HINT: Use ```data.select_dtypes().columns.tolist()```<br>Reference: [w3schools](https://www.w3schools.com/python/pandas/ref_df_select_dtypes.asp#:~:text=The%20select_dtypes()%20method%20returns,the%20specified%20dtype(s).&text=Note%3A%20You%20must%20specify%20at,you%20will%20get%20an%20error.)"
      ],
      "metadata": {
        "id": "TBg-lPJgzM4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# START CODE HERE\n",
        "object_columns = None\n",
        "non_object_columns = None\n",
        "# END CODE HERE\n",
        "print(f\"Object Columns: {object_columns}\\nNon Object Columns: {non_object_columns}\")"
      ],
      "metadata": {
        "id": "cIIKd53NpRKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST** (DON'T EDIT THIS CELL)"
      ],
      "metadata": {
        "id": "KYlrJpdaAyKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T EDIT THIS CELL\n",
        "if (object_columns == ['Cloud Cover', 'Season', 'Location', 'Weather Type'] and non_object_columns == ['Temperature', 'Humidity', 'Wind Speed', 'Precipitation (%)', 'Atmospheric Pressure', 'UV Index', 'Visibility (km)']):\n",
        "  print(f\"\\033[32mTest Passed\\033[0m\")\n",
        "else:\n",
        "  print(f\"\\033[31mTest Failed\\033[0m\")"
      ],
      "metadata": {
        "id": "z4-pWLR5_fVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CODE**\n",
        "\n",
        "We need to convert the object-type columns data into integral labels and scale the non-object-type columns data.\n",
        "\n",
        "HINT: Use ```ColumnTransformer()```<br>Reference: [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html), [ChatGPT](https://chatgpt.com/c/7f3c1b02-5da0-4c34-bdb2-d999dccb9c2f)"
      ],
      "metadata": {
        "id": "reVHprk6z_nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# START CODE HERE\n",
        "\n",
        "column_transformer = None\n",
        "\n",
        "# Fit and transform the data\n",
        "data_scaled_labeled = None\n",
        "\n",
        "# END CODE HERE\n",
        "\n",
        "all_columns = object_columns + non_object_columns\n",
        "\n",
        "# Create the new DataFrame\n",
        "data_scaled_labeled = pd.DataFrame(data_scaled_labeled, columns=all_columns)"
      ],
      "metadata": {
        "id": "kVT5qfqarRhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST** (DON'T EDIT THIS CELL)"
      ],
      "metadata": {
        "id": "2AvKGjfJk3cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T EDIT THIS CELL\n",
        "\n",
        "data_scaled_labeled_check = pd.read_csv(\"/content/data_scaled_labeled_check.csv\")\n",
        "import numpy as np\n",
        "data_scaled_labeled_values = np.sort(data_scaled_labeled.values,axis=0)\n",
        "data_scaled_labeled_check_values = np.sort(data_scaled_labeled_check.values,axis=0)\n",
        "if np.allclose(data_scaled_labeled_values, data_scaled_labeled_check_values, equal_nan=True):\n",
        "  print(f\"\\033[32mTest Passed\\033[0m\")\n",
        "else:\n",
        "  print(f\"\\033[31mTest Failed\\033[0m\")"
      ],
      "metadata": {
        "id": "7mT4H6o5D-mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting"
      ],
      "metadata": {
        "id": "wpIxEziM2EYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CODE**\n",
        "\n",
        "We need to drop the Weather Type column from data_scaled_labeled to get the X and pick Weather Type column to get Y\n",
        "\n",
        "Use 90-10 split of data, i.e. 90% for training, 10% for testing"
      ],
      "metadata": {
        "id": "GKCxivFq1rjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = None\n",
        "y = None\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(None,None, train_size = None, random_state = 10)"
      ],
      "metadata": {
        "id": "e-gDICS-mZYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST** (DON'T EDIT THIS CELL)"
      ],
      "metadata": {
        "id": "WjR9MqGMpJ82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T EDIT THIS CELL\n",
        "\n",
        "if (len(X_train)==11880 and len(X_test)==1320):\n",
        "  print(f\"\\033[32mTest Passed\\033[0m\")\n",
        "else:\n",
        "  print(f\"\\033[31mTest Failed\\033[0m\")\n",
        "\n",
        "if (len(y_train)==11880 and len(y_test)==1320):\n",
        "  print(f\"\\033[32mTest Passed\\033[0m\")\n",
        "else:\n",
        "  print(f\"\\033[31mTest Failed\\033[0m\")"
      ],
      "metadata": {
        "id": "q5ZtYcaxKzFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "uwYLbRwPzNBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing\n",
        "Use any suitable classifier to fit the training data and check the accuracy on test data\n",
        "\n",
        "Don't forget to import that library"
      ],
      "metadata": {
        "id": "upeKo2UVs8WH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CODE**\n",
        "\n",
        "ACCURACY should be more than 90%,\n",
        "\n",
        "1. Fit the model to X_train and y_train\n",
        "2. Find the model score on X_test and y_test"
      ],
      "metadata": {
        "id": "amPA5lMY3adM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# START CODE HERE\n",
        "\n",
        "from None import None\n",
        "\n",
        "model =\n",
        "model.fit(None,None)\n",
        "score = model.score(X_test,y_test)\n",
        "\n",
        "# END CODE HERE\n",
        "\n",
        "print(\"Accuracy:\", score*100)"
      ],
      "metadata": {
        "id": "yei6MWgW0Si9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST** (DON'T EDIT THIS CELL)"
      ],
      "metadata": {
        "id": "gv0LHa5FuDSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T EDIT THIS CELL\n",
        "\n",
        "if (score>0.90):\n",
        "  print(f\"\\033[32mTest Passed\\033[0m\")\n",
        "else:\n",
        "  print(f\"\\033[31mTest Failed\\033[0m\")"
      ],
      "metadata": {
        "id": "WYopYL5MuAam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Output (Here, Weather Type) (Optional)"
      ],
      "metadata": {
        "id": "pOnUEVEsuQlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = X_test.head()\n",
        "input"
      ],
      "metadata": {
        "id": "oAvmODuFwDNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = model.predict(input)\n",
        "y"
      ],
      "metadata": {
        "id": "jZAkEyqUONIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the outputs are in numbers. We can perform inverse column transfer for getiing the string values.\n"
      ],
      "metadata": {
        "id": "zuNM1UNPyY7p"
      }
    }
  ]
}